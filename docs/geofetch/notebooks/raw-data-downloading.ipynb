{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# geofetch tutorial for raw data\n",
    "\n",
    "The [GSE67303 data set](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE67303) has about 250 mb of data across 4 samples, so it's a quick download for a test case. Let's take a quick peek at the geofetch version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geofetch 0.10.1\n"
     ]
    }
   ],
   "source": [
    "geofetch --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see your CLI options, invoke `geofetch -h`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: geofetch [-h] [-V] -i INPUT [-n NAME] [-m METADATA_ROOT]\n",
      "                [-u METADATA_FOLDER] [--just-metadata] [-r]\n",
      "                [--config-template CONFIG_TEMPLATE]\n",
      "                [--pipeline-samples PIPELINE_SAMPLES]\n",
      "                [--pipeline-project PIPELINE_PROJECT] [-k SKIP] [--acc-anno]\n",
      "                [--discard-soft] [--const-limit-project CONST_LIMIT_PROJECT]\n",
      "                [--const-limit-discard CONST_LIMIT_DISCARD]\n",
      "                [--attr-limit-truncate ATTR_LIMIT_TRUNCATE] [--add-dotfile]\n",
      "                [-p] [--data-source {all,samples,series}] [--filter FILTER]\n",
      "                [--filter-size FILTER_SIZE] [-g GEO_FOLDER] [-x]\n",
      "                [-b BAM_FOLDER] [-f FQ_FOLDER] [--use-key-subset] [--silent]\n",
      "                [--verbosity V] [--logdev]\n",
      "\n",
      "Automatic GEO and SRA data downloader\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  -V, --version         show program's version number and exit\n",
      "  -i INPUT, --input INPUT\n",
      "                        required: a GEO (GSE) accession, or a file with a list\n",
      "                        of GSE numbers\n",
      "  -n NAME, --name NAME  Specify a project name. Defaults to GSE number\n",
      "  -m METADATA_ROOT, --metadata-root METADATA_ROOT\n",
      "                        Specify a parent folder location to store metadata.\n",
      "                        The project name will be added as a subfolder\n",
      "                        [Default: $SRAMETA:]\n",
      "  -u METADATA_FOLDER, --metadata-folder METADATA_FOLDER\n",
      "                        Specify an absolute folder location to store metadata.\n",
      "                        No subfolder will be added. Overrides value of\n",
      "                        --metadata-root [Default: Not used (--metadata-root is\n",
      "                        used by default)]\n",
      "  --just-metadata       If set, don't actually run downloads, just create\n",
      "                        metadata\n",
      "  -r, --refresh-metadata\n",
      "                        If set, re-download metadata even if it exists.\n",
      "  --config-template CONFIG_TEMPLATE\n",
      "                        Project config yaml file template.\n",
      "  --pipeline-samples PIPELINE_SAMPLES\n",
      "                        Optional: Specify one or more filepaths to SAMPLES\n",
      "                        pipeline interface yaml files. These will be added to\n",
      "                        the project config file to make it immediately\n",
      "                        compatible with looper. [Default: null]\n",
      "  --pipeline-project PIPELINE_PROJECT\n",
      "                        Optional: Specify one or more filepaths to PROJECT\n",
      "                        pipeline interface yaml files. These will be added to\n",
      "                        the project config file to make it immediately\n",
      "                        compatible with looper. [Default: null]\n",
      "  -k SKIP, --skip SKIP  Skip some accessions. [Default: no skip].\n",
      "  --acc-anno            Optional: Produce annotation sheets for each\n",
      "                        accession. Project combined PEP for the whole project\n",
      "                        won't be produced.\n",
      "  --discard-soft        Optional: After creation of PEP files, all soft and\n",
      "                        additional files will be deleted\n",
      "  --const-limit-project CONST_LIMIT_PROJECT\n",
      "                        Optional: Limit of the number of the constant sample\n",
      "                        characters that should not be in project yaml.\n",
      "                        [Default: 50]\n",
      "  --const-limit-discard CONST_LIMIT_DISCARD\n",
      "                        Optional: Limit of the number of the constant sample\n",
      "                        characters that should not be discarded [Default: 250]\n",
      "  --attr-limit-truncate ATTR_LIMIT_TRUNCATE\n",
      "                        Optional: Limit of the number of sample characters.Any\n",
      "                        attribute with more than X characters will truncate to\n",
      "                        the first X, where X is a number of characters\n",
      "                        [Default: 500]\n",
      "  --add-dotfile         Optional: Add .pep.yaml file that points .yaml PEP\n",
      "                        file\n",
      "  --silent              Silence logging. Overrides verbosity.\n",
      "  --verbosity V         Set logging level (1-5 or logging module level name)\n",
      "  --logdev              Expand content of logging message format.\n",
      "\n",
      "processed:\n",
      "  -p, --processed       Download processed data [Default: download raw data].\n",
      "  --data-source {all,samples,series}\n",
      "                        Optional: Specifies the source of data on the GEO\n",
      "                        record to retrieve processed data, which may be\n",
      "                        attached to the collective series entity, or to\n",
      "                        individual samples. Allowable values are: samples,\n",
      "                        series or both (all). Ignored unless 'processed' flag\n",
      "                        is set. [Default: samples]\n",
      "  --filter FILTER       Optional: Filter regex for processed filenames\n",
      "                        [Default: None].Ignored unless 'processed' flag is\n",
      "                        set.\n",
      "  --filter-size FILTER_SIZE\n",
      "                        Optional: Filter size for processed files that are\n",
      "                        stored as sample repository [Default: None]. Works\n",
      "                        only for sample data. Supported input formats : 12B,\n",
      "                        12KB, 12MB, 12GB. Ignored unless 'processed' flag is\n",
      "                        set.\n",
      "  -g GEO_FOLDER, --geo-folder GEO_FOLDER\n",
      "                        Optional: Specify a location to store processed GEO\n",
      "                        files. Ignored unless 'processed' flag is\n",
      "                        set.[Default: $GEODATA:]\n",
      "\n",
      "raw:\n",
      "  -x, --split-experiments\n",
      "                        Split SRR runs into individual samples. By default,\n",
      "                        SRX experiments with multiple SRR Runs will have a\n",
      "                        single entry in the annotation table, with each run as\n",
      "                        a separate row in the subannotation table. This\n",
      "                        setting instead treats each run as a separate sample\n",
      "  -b BAM_FOLDER, --bam-folder BAM_FOLDER\n",
      "                        Optional: Specify folder of bam files. Geofetch will\n",
      "                        not download sra files when corresponding bam files\n",
      "                        already exist. [Default: $SRABAM:]\n",
      "  -f FQ_FOLDER, --fq-folder FQ_FOLDER\n",
      "                        Optional: Specify folder of fastq files. Geofetch will\n",
      "                        not download sra files when corresponding fastq files\n",
      "                        already exist. [Default: $SRAFQ:]\n",
      "  --use-key-subset      Use just the keys defined in this module when writing\n",
      "                        out metadata.\n"
     ]
    }
   ],
   "source": [
    "geofetch -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling geofetch will do 4 tasks: \n",
    "\n",
    "1. download all `.sra` files from `GSE#####` into your SRA folder (wherever you have configured `sratools` to stick data).\n",
    "2. download all metadata from GEO and SRA and store in your metadata folder.\n",
    "2. produce a PEP-compatible sample table, `PROJECT_NAME_annotation.csv`, in your metadata folder.\n",
    "3. produce a PEP-compatible project configuration file, `PROJECT_NAME_config.yaml`, in your metadata folder.\n",
    "\n",
    "Complete details about geofetch outputs is cataloged in the [metadata outputs reference](metadata_output.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data\n",
    "\n",
    "First, create the metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata folder: /home/bnt4me/Virginia/repos/geof2/geofetch/docs_jupyter/red_algae\n",
      "Trying GSE67303 (not a file) as accession...\n",
      "Skipped 0 accessions. Starting now.\n",
      "\u001b[38;5;200mProcessing accession 1 of 1: 'GSE67303'\u001b[0m\n",
      "--2022-07-08 12:39:24--  https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?targ=gse&acc=GSE67303&form=text&view=full\n",
      "Resolving www.ncbi.nlm.nih.gov (www.ncbi.nlm.nih.gov)... 2607:f220:41e:4290::110, 130.14.29.110\n",
      "Connecting to www.ncbi.nlm.nih.gov (www.ncbi.nlm.nih.gov)|2607:f220:41e:4290::110|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [geo/text]\n",
      "Saving to: ‘/home/bnt4me/Virginia/repos/geof2/geofetch/docs_jupyter/red_algae/GSE67303_GSE.soft’\n",
      "\n",
      "/home/bnt4me/Virgin     [ <=>                ]   3.19K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-07-08 12:39:24 (134 MB/s) - ‘/home/bnt4me/Virginia/repos/geof2/geofetch/docs_jupyter/red_algae/GSE67303_GSE.soft’ saved [3266]\n",
      "\n",
      "--2022-07-08 12:39:24--  https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?targ=gsm&acc=GSE67303&form=text&view=full\n",
      "Resolving www.ncbi.nlm.nih.gov (www.ncbi.nlm.nih.gov)... 2607:f220:41e:4290::110, 130.14.29.110\n",
      "Connecting to www.ncbi.nlm.nih.gov (www.ncbi.nlm.nih.gov)|2607:f220:41e:4290::110|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [geo/text]\n",
      "Saving to: ‘/home/bnt4me/Virginia/repos/geof2/geofetch/docs_jupyter/red_algae/GSE67303_GSM.soft’\n",
      "\n",
      "/home/bnt4me/Virgin     [ <=>                ]  10.70K  --.-KB/s    in 0.05s   \n",
      "\n",
      "2022-07-08 12:39:24 (218 KB/s) - ‘/home/bnt4me/Virginia/repos/geof2/geofetch/docs_jupyter/red_algae/GSE67303_GSM.soft’ saved [10956]\n",
      "\n",
      "Processed 4 samples.\n",
      "Found SRA Project accession: SRP056574\n",
      "Downloading SRP056574 sra metadata\n",
      "Parsing SRA file to download SRR records\n",
      "sample_name does not exist, creating new...\n",
      "Getting SRR: SRR1930183 (SRX969073)\n",
      "Dry run (no raw data will be download)\n",
      "sample_name does not exist, creating new...\n",
      "Getting SRR: SRR1930184 (SRX969074)\n",
      "Dry run (no raw data will be download)\n",
      "sample_name does not exist, creating new...\n",
      "Getting SRR: SRR1930185 (SRX969075)\n",
      "Dry run (no raw data will be download)\n",
      "sample_name does not exist, creating new...\n",
      "Getting SRR: SRR1930186 (SRX969076)\n",
      "Dry run (no raw data will be download)\n",
      "Finished processing 1 accession(s)\n",
      "Creating complete project annotation sheets and config file...\n",
      "Sample annotation sheet: /home/bnt4me/Virginia/repos/geof2/geofetch/docs_jupyter/red_algae/GSE67303_annotation.csv\n",
      "Writing: /home/bnt4me/Virginia/repos/geof2/geofetch/docs_jupyter/red_algae/GSE67303_annotation.csv\n",
      "  Config file: /home/bnt4me/Virginia/repos/geof2/geofetch/docs_jupyter/red_algae/GSE67303_config.yaml\n"
     ]
    }
   ],
   "source": [
    "geofetch -i GSE67303 -n red_algae -m `pwd` --just-metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `-m` parameter specifies to use the current directory, storing the data according to the name (`-n`) parameter. So, we'll now have a `red_alga` subfolder, where the results will be saved. Inside that folder you'll see the output of the command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSE67303_annotation.csv  GSE67303_GSE.soft  GSE67303_SRA.csv\n",
      "GSE67303_config.yaml     GSE67303_GSM.soft\n"
     ]
    }
   ],
   "source": [
    "ls red_algae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.soft` files are the direct output from GEO, which contain all the metadata as stored by GEO, for both the experiment (`_GSE`) and for the individual samples (`_GSM`). Geofetch also produces a `csv` file with the SRA metadata. The filtered version (ending in `_filt`) would contain only the specified subset of the samples if we didn't request them all, but in this case, since we only gave an accession, it is identical to the complete file.\n",
    "\n",
    "Finally, there are the 2 files that make up the PEP: the `_config.yaml` file and the `_annotation.csv` file. Let's see what's in these files now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Autogenerated by geofetch\n",
      "\n",
      "name: GSE67303\n",
      "pep_version: 2.1.0\n",
      "sample_table: GSE67303_annotation.csv\n",
      "subsample_table: null\n",
      "\n",
      "looper:\n",
      "  output_dir: GSE67303\n",
      "  pipeline_interfaces: {pipeline_interfaces}\n",
      "\n",
      "sample_modifiers:\n",
      "  append:\n",
      "    Sample_growth_protocol_ch1: Cyanidioschyzon merolae cells were grown in 2xMA media\n",
      "    Sample_data_processing: Supplementary_files_format_and_content: Excel spreadsheet includes FPKM values for Darkness and Blue-Light exposed samples with p and q values of cuffdiff output.\n",
      "    Sample_extract_protocol_ch1: RNA libraries were prepared for sequencing using standard Illumina protocols\n",
      "    Sample_treatment_protocol_ch1: Cells were exposed to blue-light (15 µmole m-2s-1) for 30 minutes\n",
      "    SRR_files: SRA\n",
      "    \n",
      "  derive:\n",
      "    attributes: [read1, read2, SRR_files]\n",
      "    sources:\n",
      "      SRA: \"${SRABAM}/{SRR}.bam\"\n",
      "      FQ: \"${SRAFQ}/{SRR}.fastq.gz\"\n",
      "      FQ1: \"${SRAFQ}/{SRR}_1.fastq.gz\"\n",
      "      FQ2: \"${SRAFQ}/{SRR}_2.fastq.gz\"      \n",
      "  imply:\n",
      "    - if: \n",
      "        organism: \"Mus musculus\"\n",
      "      then:\n",
      "        genome: mm10\n",
      "    - if: \n",
      "        organism: \"Homo sapiens\"\n",
      "      then:\n",
      "        genome: hg38          \n",
      "    - if: \n",
      "        read_type: \"PAIRED\"\n",
      "      then:\n",
      "        read1: FQ1\n",
      "        read2: FQ2          \n",
      "    - if: \n",
      "        read_type: \"SINGLE\"\n",
      "      then:\n",
      "        read1: FQ1\n",
      "\n",
      "project_modifiers:\n",
      "  amend:\n",
      "    sra_convert:\n",
      "      looper:\n",
      "        results_subdir: sra_convert_results\n",
      "      sample_modifiers:\n",
      "        append:\n",
      "          SRR_files: SRA\n",
      "          pipeline_interfaces: ${CODE}/geofetch/pipeline_interface_convert.yaml\n",
      "        derive:\n",
      "          attributes: [read1, read2, SRR_files]\n",
      "          sources:\n",
      "            SRA: \"${SRARAW}/{SRR}.sra\"\n",
      "            FQ: \"${SRAFQ}/{SRR}.fastq.gz\"\n",
      "            FQ1: \"${SRAFQ}/{SRR}_1.fastq.gz\"\n",
      "            FQ2: \"${SRAFQ}/{SRR}_2.fastq.gz\"\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat red_algae/GSE67303_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two important things to note in his file: First, see in the PEP that `sample_table` points to the csv file produced by geofetch. Second, look at the amendment called `sra_convert`. This adds a pipeline interface to the sra conversion pipeline, and adds derived attributes for SRA files and fastq files that rely on environment variables called `$SRARAW` and `$SRAFQ`. These environment variables should point to folders where you store your raw .sra files and the converted fastq files.\n",
    "\n",
    "Now let's look at the first 100 characters of the csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_name,protocol,organism,read_type,data_source,SRR,SRX,Sample_title,Sample_geo_accession,Sample\n",
      "Cm_BlueLight_Rep1,cDNA,Cyanidioschyzon merolae strain 10D,PAIRED,SRA,SRR1930183,SRX969073,Cm_BlueLig\n",
      "Cm_BlueLight_Rep2,cDNA,Cyanidioschyzon merolae strain 10D,PAIRED,SRA,SRR1930184,SRX969074,Cm_BlueLig\n",
      "Cm_Darkness_Rep1,cDNA,Cyanidioschyzon merolae strain 10D,PAIRED,SRA,SRR1930185,SRX969075,Cm_Darkness\n",
      "Cm_Darkness_Rep2,cDNA,Cyanidioschyzon merolae strain 10D,PAIRED,SRA,SRR1930186,SRX969076,Cm_Darkness\n"
     ]
    }
   ],
   "source": [
    "cut -c -100 red_algae/GSE67303_annotation.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's download the actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata folder: /home/bnt4me/Virginia/repos/geof2/geofetch/docs_jupyter/red_algae\n",
      "Trying GSE67303 (not a file) as accession...\n",
      "Skipped 0 accessions. Starting now.\n",
      "\u001b[38;5;200mProcessing accession 1 of 1: 'GSE67303'\u001b[0m\n",
      "Found previous GSE file: /home/bnt4me/Virginia/repos/geof2/geofetch/docs_jupyter/red_algae/GSE67303_GSE.soft\n",
      "Found previous GSM file: /home/bnt4me/Virginia/repos/geof2/geofetch/docs_jupyter/red_algae/GSE67303_GSM.soft\n",
      "Processed 4 samples.\n",
      "Found SRA Project accession: SRP056574\n",
      "Found SRA metadata, opening..\n",
      "Parsing SRA file to download SRR records\n",
      "sample_name does not exist, creating new...\n",
      "Getting SRR: SRR1930183 (SRX969073)\n",
      "\n",
      "2022-07-08T16:40:20 prefetch.2.11.2: Current preference is set to retrieve SRA Normalized Format files with full base quality scores.\n",
      "2022-07-08T16:40:20 prefetch.2.11.2: 1) Downloading 'SRR1930183'...\n",
      "2022-07-08T16:40:20 prefetch.2.11.2: SRA Normalized Format file is being retrieved, if this is different from your preference, it may be due to current file availability.\n",
      "2022-07-08T16:40:20 prefetch.2.11.2:  Downloading via HTTPS...\n",
      "2022-07-08T16:41:28 prefetch.2.11.2:  HTTPS download succeed\n",
      "2022-07-08T16:41:28 prefetch.2.11.2:  'SRR1930183' is valid\n",
      "2022-07-08T16:41:28 prefetch.2.11.2: 1) 'SRR1930183' was downloaded successfully\n",
      "2022-07-08T16:41:28 prefetch.2.11.2: 'SRR1930183' has 0 unresolved dependencies\n",
      "sample_name does not exist, creating new...\n",
      "Getting SRR: SRR1930184 (SRX969074)\n",
      "\n",
      "2022-07-08T16:41:39 prefetch.2.11.2: Current preference is set to retrieve SRA Normalized Format files with full base quality scores.\n",
      "2022-07-08T16:41:40 prefetch.2.11.2: 1) Downloading 'SRR1930184'...\n",
      "2022-07-08T16:41:40 prefetch.2.11.2: SRA Normalized Format file is being retrieved, if this is different from your preference, it may be due to current file availability.\n",
      "2022-07-08T16:41:40 prefetch.2.11.2:  Downloading via HTTPS...\n",
      "2022-07-08T16:42:43 prefetch.2.11.2:  HTTPS download succeed\n",
      "2022-07-08T16:42:43 prefetch.2.11.2:  'SRR1930184' is valid\n",
      "2022-07-08T16:42:43 prefetch.2.11.2: 1) 'SRR1930184' was downloaded successfully\n",
      "2022-07-08T16:42:43 prefetch.2.11.2: 'SRR1930184' has 0 unresolved dependencies\n",
      "sample_name does not exist, creating new...\n",
      "Getting SRR: SRR1930185 (SRX969075)\n",
      "\n",
      "2022-07-08T16:42:54 prefetch.2.11.2: Current preference is set to retrieve SRA Normalized Format files with full base quality scores.\n",
      "2022-07-08T16:42:55 prefetch.2.11.2: 1) Downloading 'SRR1930185'...\n",
      "2022-07-08T16:42:55 prefetch.2.11.2: SRA Normalized Format file is being retrieved, if this is different from your preference, it may be due to current file availability.\n",
      "2022-07-08T16:42:55 prefetch.2.11.2:  Downloading via HTTPS...\n",
      "2022-07-08T16:45:00 prefetch.2.11.2:  HTTPS download succeed\n",
      "2022-07-08T16:45:00 prefetch.2.11.2:  'SRR1930185' is valid\n",
      "2022-07-08T16:45:00 prefetch.2.11.2: 1) 'SRR1930185' was downloaded successfully\n",
      "2022-07-08T16:45:00 prefetch.2.11.2: 'SRR1930185' has 0 unresolved dependencies\n",
      "sample_name does not exist, creating new...\n",
      "Getting SRR: SRR1930186 (SRX969076)\n",
      "\n",
      "2022-07-08T16:45:11 prefetch.2.11.2: Current preference is set to retrieve SRA Normalized Format files with full base quality scores.\n",
      "2022-07-08T16:45:12 prefetch.2.11.2: 1) Downloading 'SRR1930186'...\n",
      "2022-07-08T16:45:12 prefetch.2.11.2: SRA Normalized Format file is being retrieved, if this is different from your preference, it may be due to current file availability.\n",
      "2022-07-08T16:45:12 prefetch.2.11.2:  Downloading via HTTPS...\n",
      "2022-07-08T16:46:49 prefetch.2.11.2:  HTTPS download succeed\n",
      "2022-07-08T16:46:49 prefetch.2.11.2:  'SRR1930186' is valid\n",
      "2022-07-08T16:46:49 prefetch.2.11.2: 1) 'SRR1930186' was downloaded successfully\n",
      "2022-07-08T16:46:49 prefetch.2.11.2: 'SRR1930186' has 0 unresolved dependencies\n",
      "Finished processing 1 accession(s)\n",
      "Creating complete project annotation sheets and config file...\n",
      "Sample annotation sheet: /home/bnt4me/Virginia/repos/geof2/geofetch/docs_jupyter/red_algae/GSE67303_annotation.csv\n",
      "Writing: /home/bnt4me/Virginia/repos/geof2/geofetch/docs_jupyter/red_algae/GSE67303_annotation.csv\n",
      "  Config file: /home/bnt4me/Virginia/repos/geof2/geofetch/docs_jupyter/red_algae/GSE67303_config.yaml\n"
     ]
    }
   ],
   "source": [
    "geofetch -i GSE67303 -n red_algae -m `pwd`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Finalize the project config and sample annotation\n",
    "\n",
    "That's basically it! `geofetch` will have produced a general-purpose PEP for you, but you'll need to modify it for whatever purpose you have. For example, one common thing is to link to the pipeline you want to use by adding a `pipeline_interface` to the project config file. You may also need to adjust the `sample_annotation` file to make sure you have the right column names and attributes needed by the pipeline you're using. GEO submitters are notoriously bad at getting the metadata correct.\n",
    "\n",
    "\n",
    "## Selecting samples to download.\n",
    "\n",
    "By default, `geofetch` downloads all the data for one accession of interest. If you need more fine-grained control, either because you have multiple accessions or you need a subset of samples within them, you can use the [file-based sample specification](file-specification.md).\n",
    "\n",
    "\n",
    "## Tips\n",
    "\n",
    "* Set an environment variable for `$SRABAM` (where `.bam` files will live), and `geofetch` will check to see if you have an already-converted bamfile there before issuing the command to download the `sra` file. In this way, you can delete old `sra` files after conversion and not have to worry about re-downloading them. \n",
    "\n",
    "* The config template uses an environment variable `$SRARAW` for where `.sra` files will live. If you set this variable to the same place you instructed `sratoolkit` to download `sra` files, you won't have to tweak the config file. For more information refer to the [`sratools` page](howto-location.md).\n",
    "\n",
    "You can find a complete example of [using `geofetch` for RNA-seq data](https://github.com/databio/example-projects/tree/master/rna-seq). \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
